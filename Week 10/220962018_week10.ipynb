{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Week 10 Lab Questions"
      ],
      "metadata": {
        "id": "Rn2oXA--K-3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "wscPjrUoJZYP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Implement Auto-Encoder for latent representation of MNIST dataset."
      ],
      "metadata": {
        "id": "kSNM_ZBpLqUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Encoder maps 784 -> 100 -> 10 (latent representation)\n",
        "        self.Encoder = nn.Sequential(\n",
        "            nn.Linear(784, 100, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(100, 10, bias=True),\n",
        "            nn.Sigmoid(),  # Ensures latent values are between 0 and 1\n",
        "        )\n",
        "        # Decoder reconstructs the image from the latent vector\n",
        "        self.Decoder = nn.Sequential(\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.Linear(10, 100, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 100, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 784, bias=True),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent = self.Encoder(x)\n",
        "        x_reconstructed = self.Decoder(latent)\n",
        "        return latent, x_reconstructed.view(-1, 1, 28, 28)\n",
        "\n",
        "def loss_function(x, x_hat):\n",
        "    # Reconstruction loss only (binary cross entropy)\n",
        "    return F.binary_cross_entropy(x_hat, x, reduction='sum')\n",
        "\n",
        "# MNIST DataLoader\n",
        "batch_size = 128\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Set device, instantiate model, optimizer, and loss function\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AutoEncoder().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "def train_one_epoch(epoch_index):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for i, data in enumerate(train_data_loader):\n",
        "        inputs, _ = data\n",
        "        inputs = inputs.to(device)\n",
        "        # Flatten the input images to a 784-dimensional vector\n",
        "        inputs_flat = inputs.view(inputs.size(0), -1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        latent, outputs = model(inputs_flat)\n",
        "        loss = loss_function(inputs, outputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / (len(train_data_loader) * batch_size)\n",
        "\n",
        "def generate_digit():\n",
        "    model.eval()\n",
        "    # Sample a random latent vector from a uniform distribution in [0,1]\n",
        "    latent_sample = torch.rand((1, 10))\n",
        "    x_decoded = model.Decoder(latent_sample.to(device))\n",
        "    digit = x_decoded.detach().cpu().reshape(28, 28)\n",
        "    plt.imshow(digit, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Example training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    avg_loss = train_one_epoch(epoch)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {avg_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg_RbgzkJQsl",
        "outputId": "c134a28c-c4b3-42e2-cafc-660e4625402b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 168.84271999920355\n",
            "Epoch 2, Loss: 123.28715734746156\n",
            "Epoch 3, Loss: 115.57096251140017\n",
            "Epoch 4, Loss: 112.33310876777178\n",
            "Epoch 5, Loss: 110.20255762681778\n",
            "Epoch 6, Loss: 108.71214728772259\n",
            "Epoch 7, Loss: 107.40109370054721\n",
            "Epoch 8, Loss: 106.47127627309706\n",
            "Epoch 9, Loss: 105.63132172606902\n",
            "Epoch 10, Loss: 104.94819367821538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a reconstructed digit using a random latent vector\n",
        "generate_digit()\n",
        "generate_digit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "id": "rjKpIqXtJji-",
        "outputId": "70cd3b24-1ad0-42fb-a467-5f885efee874"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Implement VAE for synthesizing digits using MNIST training data."
      ],
      "metadata": {
        "id": "6Cvo-Hc8Lx2_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PR0eE1pC_vm",
        "outputId": "e48829a7-7dc9-4de5-ccc3-db8aac594d81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 211.2582610888776\n",
            "Epoch 2, Loss: 175.55275283846012\n",
            "Epoch 3, Loss: 164.04321007637074\n",
            "Epoch 4, Loss: 158.7026914584357\n",
            "Epoch 5, Loss: 155.50068566946587\n",
            "Epoch 6, Loss: 153.19169148199086\n",
            "Epoch 7, Loss: 151.607382556777\n",
            "Epoch 8, Loss: 150.46769584216543\n",
            "Epoch 9, Loss: 149.44789149562942\n",
            "Epoch 10, Loss: 148.78478252353952\n"
          ]
        }
      ],
      "source": [
        "class VariationalAutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Encoder maps 784 -> 100 -> 10\n",
        "        self.Encoder = nn.Sequential(\n",
        "            nn.Linear(784, 100, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(100, 10, bias=True),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        # Compute latent mean and log variance from the encoder output (10-dimensional)\n",
        "        self.mean = nn.Linear(10, 10, bias=True)\n",
        "        self.log_var = nn.Linear(10, 10, bias=True)\n",
        "\n",
        "        self.Decoder = nn.Sequential(\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.Linear(10, 100, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 100, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 784, bias=True),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc = self.Encoder(x)\n",
        "        mean = self.mean(enc)\n",
        "        log_var = self.log_var(enc)\n",
        "        # Reparameterization trick\n",
        "        z = mean + torch.exp(0.5 * log_var) * torch.randn_like(log_var)\n",
        "        y = self.Decoder(z)\n",
        "        return mean, log_var, y.view(-1, 1, 28, 28)\n",
        "\n",
        "def loss_function(x, x_hat, mean, log_var):\n",
        "    reproduction_loss = F.binary_cross_entropy(x_hat, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
        "    return reproduction_loss + KLD\n",
        "\n",
        "# MNIST DataLoader\n",
        "batch_size = 128\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Set device, instantiate model, optimizer, and loss function\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = VariationalAutoEncoder().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = loss_function\n",
        "\n",
        "def train_one_epoch(epoch_index):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for i, data in enumerate(train_data_loader):\n",
        "        inputs, _ = data\n",
        "        inputs = inputs.to(device)\n",
        "        # Flatten the input images to a 784-dimensional vector\n",
        "        inputs_flat = inputs.view(inputs.size(0), -1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        mean, log_var, outputs = model(inputs_flat)\n",
        "        loss = loss_fn(inputs, outputs, mean, log_var)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / (len(train_data_loader) * batch_size)\n",
        "\n",
        "def generate_digit():\n",
        "    model.eval()\n",
        "    # Sample from a standard normal latent space\n",
        "    mean = torch.zeros((1, 10))\n",
        "    var = torch.ones((1, 10))\n",
        "    z_sample = mean + var * torch.randn_like(var)\n",
        "    x_decoded = model.Decoder(z_sample.to(device))\n",
        "    digit = x_decoded.detach().cpu().reshape(28, 28)\n",
        "    plt.imshow(digit, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Example training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    avg_loss = train_one_epoch(epoch)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {avg_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a synthesized digit after training\n",
        "generate_digit()\n",
        "generate_digit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "id": "XLXJ-Hf5E-DD",
        "outputId": "ff49c607-1c63-4949-96db-c4da5e21df4b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}